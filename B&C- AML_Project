{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[],"authorship_tag":"ABX9TyNmKw4+2TE3Mkgy2MMnblry"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"},"accelerator":"GPU","gpuClass":"standard"},"cells":[{"cell_type":"code","source":["import torch\n","\n","!pip uninstall torch-scatter torch-sparse torch-geometric torch-cluster  --y\n","!pip install torch-scatter -f https://data.pyg.org/whl/torch-{torch.__version__}.html\n","!pip install torch-sparse -f https://data.pyg.org/whl/torch-{torch.__version__}.html\n","!pip install torch-cluster -f https://data.pyg.org/whl/torch-{torch.__version__}.html\n","!pip install git+https://github.com/pyg-team/pytorch_geometric.git"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":1000},"id":"DfH4m9A5BJn3","executionInfo":{"status":"ok","timestamp":1677685069393,"user_tz":-60,"elapsed":48715,"user":{"displayName":"Marco Acerbis","userId":"06213734805574553664"}},"outputId":"f0679e77-b142-4428-f511-003c96d67bfb"},"execution_count":1,"outputs":[{"output_type":"stream","name":"stdout","text":["\u001b[33mWARNING: Skipping torch-scatter as it is not installed.\u001b[0m\u001b[33m\n","\u001b[0m\u001b[33mWARNING: Skipping torch-sparse as it is not installed.\u001b[0m\u001b[33m\n","\u001b[0m\u001b[33mWARNING: Skipping torch-geometric as it is not installed.\u001b[0m\u001b[33m\n","\u001b[0m\u001b[33mWARNING: Skipping torch-cluster as it is not installed.\u001b[0m\u001b[33m\n","\u001b[0mLooking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n","Looking in links: https://data.pyg.org/whl/torch-1.13.1+cu116.html\n","Collecting torch-scatter\n","  Downloading https://data.pyg.org/whl/torch-1.13.0%2Bcu116/torch_scatter-2.1.0%2Bpt113cu116-cp38-cp38-linux_x86_64.whl (9.4 MB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m9.4/9.4 MB\u001b[0m \u001b[31m16.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hInstalling collected packages: torch-scatter\n","Successfully installed torch-scatter-2.1.0+pt113cu116\n","Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n","Looking in links: https://data.pyg.org/whl/torch-1.13.1+cu116.html\n","Collecting torch-sparse\n","  Downloading https://data.pyg.org/whl/torch-1.13.0%2Bcu116/torch_sparse-0.6.16%2Bpt113cu116-cp38-cp38-linux_x86_64.whl (4.5 MB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m4.5/4.5 MB\u001b[0m \u001b[31m23.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hRequirement already satisfied: scipy in /usr/local/lib/python3.8/dist-packages (from torch-sparse) (1.7.3)\n","Requirement already satisfied: numpy<1.23.0,>=1.16.5 in /usr/local/lib/python3.8/dist-packages (from scipy->torch-sparse) (1.22.4)\n","Installing collected packages: torch-sparse\n","Successfully installed torch-sparse-0.6.16+pt113cu116\n","Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n","Looking in links: https://data.pyg.org/whl/torch-1.13.1+cu116.html\n","Collecting torch-cluster\n","  Downloading https://data.pyg.org/whl/torch-1.13.0%2Bcu116/torch_cluster-1.6.0%2Bpt113cu116-cp38-cp38-linux_x86_64.whl (3.2 MB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m3.2/3.2 MB\u001b[0m \u001b[31m21.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hRequirement already satisfied: scipy in /usr/local/lib/python3.8/dist-packages (from torch-cluster) (1.7.3)\n","Requirement already satisfied: numpy<1.23.0,>=1.16.5 in /usr/local/lib/python3.8/dist-packages (from scipy->torch-cluster) (1.22.4)\n","Installing collected packages: torch-cluster\n","Successfully installed torch-cluster-1.6.0+pt113cu116\n","Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n","Collecting git+https://github.com/pyg-team/pytorch_geometric.git\n","  Cloning https://github.com/pyg-team/pytorch_geometric.git to /tmp/pip-req-build-hy8lq91b\n","  Running command git clone --filter=blob:none --quiet https://github.com/pyg-team/pytorch_geometric.git /tmp/pip-req-build-hy8lq91b\n","  Resolved https://github.com/pyg-team/pytorch_geometric.git to commit a8d45c31c3cb1bd8eb95e7aca70b60a526a5bb9d\n","  Installing build dependencies ... \u001b[?25l\u001b[?25hdone\n","  Getting requirements to build wheel ... \u001b[?25l\u001b[?25hdone\n","  Preparing metadata (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n","Requirement already satisfied: numpy in /usr/local/lib/python3.8/dist-packages (from torch-geometric==2.3.0) (1.22.4)\n","Requirement already satisfied: requests in /usr/local/lib/python3.8/dist-packages (from torch-geometric==2.3.0) (2.25.1)\n","Requirement already satisfied: pyparsing in /usr/local/lib/python3.8/dist-packages (from torch-geometric==2.3.0) (3.0.9)\n","Requirement already satisfied: tqdm in /usr/local/lib/python3.8/dist-packages (from torch-geometric==2.3.0) (4.64.1)\n","Collecting psutil>=5.8.0\n","  Downloading psutil-5.9.4-cp36-abi3-manylinux_2_12_x86_64.manylinux2010_x86_64.manylinux_2_17_x86_64.manylinux2014_x86_64.whl (280 kB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m280.2/280.2 KB\u001b[0m \u001b[31m16.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hRequirement already satisfied: scikit-learn in /usr/local/lib/python3.8/dist-packages (from torch-geometric==2.3.0) (1.0.2)\n","Requirement already satisfied: jinja2 in /usr/local/lib/python3.8/dist-packages (from torch-geometric==2.3.0) (3.1.2)\n","Requirement already satisfied: scipy in /usr/local/lib/python3.8/dist-packages (from torch-geometric==2.3.0) (1.7.3)\n","Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.8/dist-packages (from jinja2->torch-geometric==2.3.0) (2.1.2)\n","Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.8/dist-packages (from requests->torch-geometric==2.3.0) (2.10)\n","Requirement already satisfied: chardet<5,>=3.0.2 in /usr/local/lib/python3.8/dist-packages (from requests->torch-geometric==2.3.0) (4.0.0)\n","Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.8/dist-packages (from requests->torch-geometric==2.3.0) (2022.12.7)\n","Requirement already satisfied: urllib3<1.27,>=1.21.1 in /usr/local/lib/python3.8/dist-packages (from requests->torch-geometric==2.3.0) (1.26.14)\n","Requirement already satisfied: joblib>=0.11 in /usr/local/lib/python3.8/dist-packages (from scikit-learn->torch-geometric==2.3.0) (1.2.0)\n","Requirement already satisfied: threadpoolctl>=2.0.0 in /usr/local/lib/python3.8/dist-packages (from scikit-learn->torch-geometric==2.3.0) (3.1.0)\n","Building wheels for collected packages: torch-geometric\n","  Building wheel for torch-geometric (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n","  Created wheel for torch-geometric: filename=torch_geometric-2.3.0-py3-none-any.whl size=872958 sha256=47699df1a0f662be87630dd0dabde440157130c06af2420cb6907a0b35d2451d\n","  Stored in directory: /tmp/pip-ephem-wheel-cache-fjlbtxm4/wheels/ba/e1/8e/28297c3201c884d3ea8c47ba71a9e71e547e556c0caa9cf5a2\n","Successfully built torch-geometric\n","Installing collected packages: psutil, torch-geometric\n","  Attempting uninstall: psutil\n","    Found existing installation: psutil 5.4.8\n","    Uninstalling psutil-5.4.8:\n","      Successfully uninstalled psutil-5.4.8\n","Successfully installed psutil-5.9.4 torch-geometric-2.3.0\n"]},{"output_type":"display_data","data":{"application/vnd.colab-display-data+json":{"pip_warning":{"packages":["psutil"]}}},"metadata":{}}]},{"cell_type":"code","execution_count":2,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"GZ2c2Eu6AkBK","executionInfo":{"status":"ok","timestamp":1677685095285,"user_tz":-60,"elapsed":25896,"user":{"displayName":"Marco Acerbis","userId":"06213734805574553664"}},"outputId":"88037924-f527-4551-df4c-0619d5a2517d"},"outputs":[{"output_type":"stream","name":"stderr","text":["Downloading https://data.pyg.org/datasets/elliptic/elliptic_txs_features.csv.zip\n","Extracting Elliptic/raw/elliptic_txs_features.csv.zip\n","Downloading https://data.pyg.org/datasets/elliptic/elliptic_txs_edgelist.csv.zip\n","Extracting Elliptic/raw/elliptic_txs_edgelist.csv.zip\n","Downloading https://data.pyg.org/datasets/elliptic/elliptic_txs_classes.csv.zip\n","Extracting Elliptic/raw/elliptic_txs_classes.csv.zip\n","Processing...\n","Done!\n"]}],"source":["import os\n","import networkx as nx\n","import pandas as pd\n","import numpy as np\n","from torch_geometric.datasets import EllipticBitcoinDataset\n","import torch.nn.functional as F\n","from torch_geometric.nn import GCNConv\n","from imblearn.under_sampling import RandomUnderSampler\n","from sklearn.model_selection import train_test_split\n","import scipy.sparse as sp\n","from torch import nn\n","from sklearn.ensemble import RandomForestClassifier as RFC\n","from sklearn.metrics import confusion_matrix,f1_score, precision_score, recall_score\n","\n","dataset = EllipticBitcoinDataset(root='./Elliptic')\n"]},{"cell_type":"code","source":["class DGI(torch.nn.Module):\n","    def __init__(self, n_in, n_h, activation):\n","        super(DGI, self).__init__()\n","        self.gcn = GCN(n_in, n_h, activation)\n","        self.read = AvgReadout()\n","\n","        self.sigm = nn.Sigmoid()\n","\n","        self.disc = Discriminator(n_h)\n","\n","    def forward(self, seq1, seq2, adj, sparse, msk, samp_bias1, samp_bias2):\n","        h_1 = self.gcn(seq1, adj, sparse)\n","\n","        c = self.read(h_1, msk)\n","        c = self.sigm(c)\n","\n","        h_2 = self.gcn(seq2, adj, sparse)\n","\n","        ret = self.disc(c, h_1, h_2, samp_bias1, samp_bias2)\n","\n","        return ret\n","\n","    # Detach the return variables\n","    def embed(self, seq, adj, sparse, msk):\n","        h_1 = self.gcn(seq, adj, sparse)\n","        c = self.read(h_1, msk)\n","\n","        return h_1.detach(), c.detach()"],"metadata":{"id":"UBqzF7DwUEuC","executionInfo":{"status":"ok","timestamp":1677685095285,"user_tz":-60,"elapsed":5,"user":{"displayName":"Marco Acerbis","userId":"06213734805574553664"}}},"execution_count":3,"outputs":[]},{"cell_type":"code","source":["class Discriminator(nn.Module):\n","    def __init__(self, n_h):\n","        super(Discriminator, self).__init__()\n","        self.f_k = nn.Bilinear(n_h, n_h, 1)\n","\n","        for m in self.modules():\n","            self.weights_init(m)\n","\n","    def weights_init(self, m):\n","        if isinstance(m, nn.Bilinear):\n","            torch.nn.init.xavier_uniform_(m.weight.data)\n","            if m.bias is not None:\n","                m.bias.data.fill_(0.0)\n","\n","    def forward(self, c, h_pl, h_mi, s_bias1=None, s_bias2=None):\n","        c_x = torch.unsqueeze(c, 1)\n","        c_x = c_x.expand_as(h_pl)\n","\n","        sc_1 = torch.squeeze(self.f_k(h_pl, c_x), 2)\n","        sc_2 = torch.squeeze(self.f_k(h_mi, c_x), 2)\n","\n","        if s_bias1 is not None:\n","            sc_1 += s_bias1\n","        if s_bias2 is not None:\n","            sc_2 += s_bias2\n","\n","        logits = torch.cat((sc_1, sc_2), 1)\n","\n","        return logits\n","\n","class AvgReadout(nn.Module):\n","    def __init__(self):\n","        super(AvgReadout, self).__init__()\n","\n","    def forward(self, seq, msk):\n","        if msk is None:\n","            return torch.mean(seq, 1)\n","        else:\n","            msk = torch.unsqueeze(msk, -1)\n","            return torch.sum(seq * msk, 1) / torch.sum(msk)\n","\n","class GCN(torch.nn.Module):\n","    def __init__(self, in_ft, out_ft, act, bias=True):\n","        super(GCN, self).__init__()\n","        self.fc = nn.Linear(in_ft, out_ft, bias=False)\n","        self.act = nn.PReLU() if act == 'prelu' else act\n","        \n","        if bias:\n","            self.bias = nn.Parameter(torch.FloatTensor(out_ft))\n","            self.bias.data.fill_(0.0)\n","        else:\n","            self.register_parameter('bias', None)\n","\n","        for m in self.modules():\n","            self.weights_init(m)\n","\n","    def weights_init(self, m):\n","        if isinstance(m, nn.Linear):\n","            torch.nn.init.xavier_uniform_(m.weight.data)\n","            if m.bias is not None:\n","                m.bias.data.fill_(0.0)\n","\n","    # Shape of seq: (batch, nodes, features)\n","    def forward(self, seq, adj, sparse=False):\n","        seq_fts = self.fc(seq)\n","        if sparse:\n","            out = torch.unsqueeze(torch.spmm(adj, torch.squeeze(seq_fts, 0)), 0)\n","        else:\n","            out = torch.bmm(adj, seq_fts)\n","        if self.bias is not None:\n","            out += self.bias\n","        \n","        return self.act(out)\n","\n"],"metadata":{"id":"QvnZ5kmxPKAL","executionInfo":{"status":"ok","timestamp":1677685095286,"user_tz":-60,"elapsed":5,"user":{"displayName":"Marco Acerbis","userId":"06213734805574553664"}}},"execution_count":4,"outputs":[]},{"cell_type":"code","source":["batch_size = 1\n","nb_epochs = 1000\n","patience = 100\n","lr = 0.01\n","l2_coef = 0.0\n","drop_prob = 0.0\n","hid_units = 384\n","sparse = True\n","nonlinearity = 'prelu'"],"metadata":{"id":"cikH7rUEPjbN","executionInfo":{"status":"ok","timestamp":1677685095286,"user_tz":-60,"elapsed":5,"user":{"displayName":"Marco Acerbis","userId":"06213734805574553664"}}},"execution_count":5,"outputs":[]},{"cell_type":"code","source":["def check(name, unique):\n","    if(name not in unique):\n","        name = -1\n","    return name\n","\n","\n","def load_data(data_dir='./Elliptic/raw/', random_state=28):\n","\n","    edges = pd.read_csv(data_dir + 'elliptic_txs_edgelist.csv')\n","    features = pd.read_csv(data_dir + 'elliptic_txs_features.csv', header=None)\n","    classes = pd.read_csv(data_dir + 'elliptic_txs_classes.csv')\n","    tx_features = ['tx_feat_' + str(i) for i in range(2, 95)]\n","    agg_features = ['agg_feat_' + str(i) for i in range(1, 73)]\n","    features.columns = ['txId', 'time_step'] + tx_features + agg_features\n","    features = pd.merge(\n","        features,\n","        classes,\n","        left_on='txId',\n","        right_on='txId',\n","        how='left')\n","    features = features[features['class'] != 'unknown']\n","    ratio = sum(features['class'] == '1') * 2 * 0.25 / len(features)\n","    features, X_test, _, _ = train_test_split(\n","        features, features['class'], stratify=features['class'], random_state=random_state, test_size=ratio)\n","    X_train, X_val, y_train, y_val = train_test_split(\n","        features, features['class'], stratify=features['class'], random_state=random_state)\n","    under_sampler = RandomUnderSampler(random_state=random_state)\n","    X_train, _ = under_sampler.fit_resample(X_train, y_train)\n","    X_val, _ = under_sampler.fit_resample(X_val, y_val)\n","    idx_train = range(len(X_train))\n","    idx_val = range(len(X_train), len(X_train) + len(X_val))\n","    idx_test = range(\n","        len(X_train) +\n","        len(X_val),\n","        len(X_train) +\n","        len(X_val) +\n","        len(X_test))\n","    features = pd.concat([X_train, X_val, X_test])\n","    unique = features['txId'].unique()\n","    edges['txId1'] = edges['txId1'].apply(lambda name: check(name, unique))\n","    edges['txId2'] = edges['txId2'].apply(lambda name: check(name, unique))\n","    edges = edges[edges['txId1'] != -1]\n","    edges = edges[edges['txId2'] != -1]\n","    class_values = sorted(features['class'].unique())\n","    features_idx = {\n","        name: idx for idx,\n","        name in enumerate(\n","            sorted(\n","                features['txId'].unique()))}\n","    class_idx = {name: id for id, name in enumerate(class_values)}\n","    features['txId'] = features['txId'].apply(lambda name: features_idx[name])\n","    edges['txId1'] = edges['txId1'].apply(lambda name: features_idx[name])\n","    edges['txId2'] = edges['txId2'].apply(lambda name: features_idx[name])\n","    features['class'] = features['class'].apply(lambda name: class_idx[name])\n","    labels = features['class']\n","    classes = sorted(list(set(labels)), reverse=True)\n","    classes_dict = {\n","        c: np.identity(\n","            len(classes))[\n","            i,\n","            :] for i,\n","        c in enumerate(classes)}\n","    labels = np.array(list(map(classes_dict.get, labels)), dtype=np.int32)\n","    idx_features_labels = features.values[:, :-1]\n","    features = sp.csr_matrix(idx_features_labels[:, 1:], dtype=np.float32)\n","    edges_unordered = edges.values\n","    idx = np.array(idx_features_labels[:, 0], dtype=np.int32)\n","    idx_map = {j: i for i, j in enumerate(idx)}\n","    edges = np.array(list(map(idx_map.get, edges_unordered.flatten())),\n","                     dtype=np.int32).reshape(edges_unordered.shape)\n","    adj = sp.coo_matrix((np.ones(edges.shape[0]), (edges[:, 0], edges[:, 1])), shape=(\n","        idx_features_labels.shape[0], idx_features_labels.shape[0]), dtype=np.float32)\n","    adj = adj + adj.T.multiply(adj.T > adj) - adj.multiply(adj.T > adj)\n","    features = normalize_features(features)\n","    #adj = normalize_adj(adj + sp.eye(adj.shape[0]))\n","    #adj = torch.FloatTensor(np.array(adj.todense()))\n","    features = torch.FloatTensor(np.array(features.todense()))\n","    labels = torch.FloatTensor(np.where(labels)[1])\n","    idx_train = torch.LongTensor(idx_train)\n","    idx_val = torch.LongTensor(idx_val)\n","    idx_test = torch.LongTensor(idx_test)\n","    return adj, features, labels, idx_train, idx_val, idx_test\n","\n","\n","def normalize_adj(mx):\n","\n","    rowsum = np.array(mx.sum(1))\n","    r_inv_sqrt = np.power(rowsum, -0.5).flatten()\n","    r_inv_sqrt[np.isinf(r_inv_sqrt)] = 0.\n","    r_mat_inv_sqrt = sp.diags(r_inv_sqrt)\n","    mx = mx.dot(r_mat_inv_sqrt).transpose().dot(r_mat_inv_sqrt)\n","    return mx\n","\n","\n","def normalize_features(mx):\n","\n","    rowsum = np.array(mx.sum(1))\n","    r_inv = np.power(rowsum, -1).flatten()\n","    r_inv[np.isinf(r_inv)] = 0.\n","    r_mat_inv = sp.diags(r_inv)\n","    mx = r_mat_inv.dot(mx)\n","    return mx\n"],"metadata":{"id":"p5pXrIM5N3ae","executionInfo":{"status":"ok","timestamp":1677685095286,"user_tz":-60,"elapsed":5,"user":{"displayName":"Marco Acerbis","userId":"06213734805574553664"}}},"execution_count":6,"outputs":[]},{"cell_type":"code","source":["adj, features, labels, idx_train, idx_val, idx_test = load_data()"],"metadata":{"id":"KlOPkmhhN5hD","executionInfo":{"status":"ok","timestamp":1677685115017,"user_tz":-60,"elapsed":19736,"user":{"displayName":"Marco Acerbis","userId":"06213734805574553664"}}},"execution_count":7,"outputs":[]},{"cell_type":"code","source":["def preprocess_features(features):\n","\n","    rowsum = np.array(features.sum(1))\n","    r_inv = np.power(rowsum, -1).flatten()\n","    r_inv[np.isinf(r_inv)] = 0.\n","    r_mat_inv = sp.diags(r_inv)\n","    features = r_mat_inv.dot(features)\n","    return features\n","\n","\n","features = preprocess_features(features)"],"metadata":{"id":"WzxX1PwSOzYa","executionInfo":{"status":"ok","timestamp":1677685115017,"user_tz":-60,"elapsed":32,"user":{"displayName":"Marco Acerbis","userId":"06213734805574553664"}}},"execution_count":8,"outputs":[]},{"cell_type":"code","source":["def sparse_mx_to_torch_sparse_tensor(sparse_mx):\n","    \n","    sparse_mx = sparse_mx.tocoo().astype(np.float32)\n","    indices = torch.from_numpy(\n","        np.vstack((sparse_mx.row, sparse_mx.col)).astype(np.int64))\n","    values = torch.from_numpy(sparse_mx.data)\n","    shape = torch.Size(sparse_mx.shape)\n","    return torch.sparse.FloatTensor(indices, values, shape)\n","\n","\n","class LogReg(nn.Module):\n","    def __init__(self, ft_in, nb_classes):\n","        super(LogReg, self).__init__()\n","        self.fc = nn.Linear(ft_in, nb_classes)\n","\n","        for m in self.modules():\n","            self.weights_init(m)\n","\n","    def weights_init(self, m):\n","        if isinstance(m, nn.Linear):\n","            torch.nn.init.xavier_uniform_(m.weight.data)\n","            if m.bias is not None:\n","                m.bias.data.fill_(0.0)\n","\n","    def forward(self, seq):\n","        ret = self.fc(seq)\n","        return ret"],"metadata":{"id":"k03DL6YZSlT2","executionInfo":{"status":"ok","timestamp":1677685115018,"user_tz":-60,"elapsed":30,"user":{"displayName":"Marco Acerbis","userId":"06213734805574553664"}}},"execution_count":9,"outputs":[]},{"cell_type":"code","source":["nb_nodes = features.shape[0]\n","ft_size = features.shape[1]\n","nb_classes = labels.shape[0]\n","\n","\n","adj = normalize_adj(adj + sp.eye(adj.shape[0]))\n","\n","if sparse:\n","    sp_adj = sparse_mx_to_torch_sparse_tensor(adj)\n","else:\n","    adj = (adj + sp.eye(adj.shape[0])).todense()\n","\n","features = torch.FloatTensor(features[np.newaxis])\n","if not sparse:\n","    adj = torch.FloatTensor(adj[np.newaxis])\n","labels = torch.FloatTensor(labels[np.newaxis])\n","idx_train = torch.LongTensor(idx_train)\n","idx_val = torch.LongTensor(idx_val)\n","idx_test = torch.LongTensor(idx_test)\n","\n","model = DGI(ft_size, hid_units, nonlinearity)\n","optimiser = torch.optim.Adam(model.parameters(), lr=lr, weight_decay=l2_coef)\n","\n","if torch.cuda.is_available():\n","    print('Using CUDA')\n","    model.cuda()\n","    features = features.cuda()\n","    if sparse:\n","        sp_adj = sp_adj.cuda()\n","    else:\n","        adj = adj.cuda()\n","    labels = labels.cuda()\n","    idx_train = idx_train.cuda()\n","    idx_val = idx_val.cuda()\n","    idx_test = idx_test.cuda()\n","\n","b_xent = nn.BCEWithLogitsLoss()\n","xent = nn.CrossEntropyLoss()\n","cnt_wait = 0\n","best = 1e9\n","best_t = 0"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"dqx5k6DgA-Ge","executionInfo":{"status":"ok","timestamp":1677685121620,"user_tz":-60,"elapsed":6631,"user":{"displayName":"Marco Acerbis","userId":"06213734805574553664"}},"outputId":"6fcac740-2445-4f72-97e5-8aeee30f8677"},"execution_count":10,"outputs":[{"output_type":"stream","name":"stdout","text":["Using CUDA\n"]}]},{"cell_type":"code","source":["for epoch in range(nb_epochs):\n","    model.train()\n","    optimiser.zero_grad()\n","\n","    idx = np.random.permutation(nb_nodes)\n","    shuf_fts = features[:, idx, :]\n","\n","    lbl_1 = torch.ones(batch_size, nb_nodes)\n","    lbl_2 = torch.zeros(batch_size, nb_nodes)\n","    lbl = torch.cat((lbl_1, lbl_2), 1)\n","\n","    if torch.cuda.is_available():\n","        shuf_fts = shuf_fts.cuda()\n","        lbl = lbl.cuda()\n","    \n","    logits = model(features, shuf_fts, sp_adj if sparse else adj, sparse, None, None, None) \n","\n","    loss = b_xent(logits, lbl)\n","\n","    #print('Loss:', loss)\n","\n","    if loss < best:\n","        best = loss\n","        best_t = epoch\n","        cnt_wait = 0\n","        torch.save(model.state_dict(), 'best_dgi.pkl')\n","    else:\n","        cnt_wait += 1\n","\n","    if cnt_wait == patience:\n","        print('Early stopping!')\n","        break\n","\n","    loss.backward()\n","    optimiser.step()\n","\n","    model.load_state_dict(torch.load('best_dgi.pkl'))\n","\n","    embeds, _ = model.embed(features, sp_adj if sparse else adj, sparse, None)\n","    train_embs = embeds[0, idx_train]\n","    val_embs = embeds[0, idx_val]\n","    test_embs = embeds[0, idx_test]\n","\n","    train_lbls = labels[0, idx_train].type(torch.LongTensor)\n","    val_lbls = labels[0, idx_val].type(torch.LongTensor)\n","    test_lbls = labels[0, idx_test].type(torch.LongTensor)\n","\n","    train_lbls = train_lbls.cuda()\n","    val_lbls = val_lbls.cuda()\n","    test_lbls = test_lbls.cuda()\n","\n","    tot = torch.zeros(1)\n","    tot = tot.cuda()"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"1AxitEqCFV6l","executionInfo":{"status":"ok","timestamp":1677685140862,"user_tz":-60,"elapsed":19255,"user":{"displayName":"Marco Acerbis","userId":"06213734805574553664"}},"outputId":"e4a776ff-d841-470a-9c8c-3866592ffa82"},"execution_count":11,"outputs":[{"output_type":"stream","name":"stdout","text":["Early stopping!\n"]}]},{"cell_type":"code","source":["accs = []\n","\n","for _ in range(50):\n","    log = LogReg(hid_units, nb_classes)\n","    opt = torch.optim.Adam(log.parameters(), lr=0.01, weight_decay=0.0)\n","    log.cuda()\n","\n","    pat_steps = 0\n","    best_acc = torch.zeros(1)\n","    best_acc = best_acc.cuda()\n","    for _ in range(100):\n","        log.train()\n","        opt.zero_grad()\n","\n","        logits = log(train_embs)\n","        logits = logits.cuda()\n","        loss = xent(logits, train_lbls)\n","        \n","        loss.backward()\n","        opt.step()\n","\n","    logits = log(test_embs)\n","    preds = torch.argmax(logits, dim=1)\n","    preds = preds.cuda()\n","\n","F1 = f1_score(test_lbls.cpu(),preds.cpu(),pos_label=0)\n","Recall = recall_score(test_lbls.cpu(),preds.cpu(),pos_label=0)\n","Precision = precision_score(test_lbls.cpu(),preds.cpu(),pos_label=0)\n","cm = confusion_matrix(test_lbls.cpu(),preds.cpu())\n","\n","print('Precision: ', Precision,' Recall: ', Recall, ' F1: ', F1)\n","print(cm)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"o_ia_pG8i8My","executionInfo":{"status":"ok","timestamp":1677689041706,"user_tz":-60,"elapsed":189263,"user":{"displayName":"Marco Acerbis","userId":"06213734805574553664"}},"outputId":"c8a790b6-15b3-4b6b-9f73-8c6dbd57959c"},"execution_count":73,"outputs":[{"output_type":"stream","name":"stdout","text":["Precision:  0.9594003747657714  Recall:  0.7489029741589469  F1:  0.8411829134720702\n","[[1536  515]\n"," [  65  157]]\n"]}]},{"cell_type":"code","source":["F1 = f1_score(test_lbls.cpu(),preds.cpu(),pos_label=0)\n","Recall = recall_score(test_lbls.cpu(),preds.cpu(),pos_label=0)\n","Precision = precision_score(test_lbls.cpu(),preds.cpu(),pos_label=0)\n","\n","print('Precision: ', Precision,' Recall: ', Recall, ' F1: ', F1)\n"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"qwzfQ55V-778","executionInfo":{"status":"ok","timestamp":1677687892403,"user_tz":-60,"elapsed":1,"user":{"displayName":"Marco Acerbis","userId":"06213734805574553664"}},"outputId":"6cb768bc-5c9d-496d-98fd-b679aa901f1a"},"execution_count":71,"outputs":[{"output_type":"stream","name":"stdout","text":["Precision:  0.9664204163868368  Recall:  0.7016089712335446  F1:  0.8129943502824859\n"]}]},{"cell_type":"code","source":["data_ft = pd.read_csv('./Elliptic/raw/elliptic_txs_features.csv', header=None)\n","data_ed = pd.read_csv('./Elliptic/raw/elliptic_txs_edgelist.csv')\n","data_lb = pd.read_csv('./Elliptic/raw/elliptic_txs_classes.csv')"],"metadata":{"id":"gZkklO6R_Lag","executionInfo":{"status":"ok","timestamp":1677685336720,"user_tz":-60,"elapsed":7854,"user":{"displayName":"Marco Acerbis","userId":"06213734805574553664"}}},"execution_count":13,"outputs":[]},{"cell_type":"code","source":["dataset = data_ft.merge(data_ed, right_index=True, left_index=True)\n","dataset = dataset.merge(data_lb, right_index=True, left_index=True) \n","dataset.drop(columns=['txId'],inplace=True)\n","dataset = dataset[dataset['class'] != 'unknown']"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":488},"id":"zJjzvNPhDsOX","executionInfo":{"status":"ok","timestamp":1677685819193,"user_tz":-60,"elapsed":1498,"user":{"displayName":"Marco Acerbis","userId":"06213734805574553664"}},"outputId":"b8bfb940-50f3-4645-bfe2-8c97b695069a"},"execution_count":39,"outputs":[{"output_type":"execute_result","data":{"text/plain":["                0   1         2         3         4          5         6  \\\n","3       232438397   1  0.163054  1.963790 -0.646376  12.409294 -0.063725   \n","9       232029206   1 -0.005027  0.578941 -0.091383   4.380281 -0.063725   \n","10      232344069   1 -0.147852 -0.184668 -1.201369  -0.121970 -0.043875   \n","11       27553029   1 -0.151357 -0.184668 -1.201369  -0.121970 -0.043875   \n","16        3881097   1 -0.172306 -0.184668 -1.201369   0.028105 -0.043875   \n","...           ...  ..       ...       ...       ...        ...       ...   \n","203752   80329479  49 -0.159293 -0.037276  1.018602  -0.121970  0.035526   \n","203754  158406298  49 -0.172962 -0.126566  1.018602  -0.121970 -0.063725   \n","203759  158375075  49 -0.170412 -0.078164  1.018602   0.028105 -0.043875   \n","203763  147478192  49 -0.093732 -0.116160  1.018602  -0.121970 -0.043875   \n","203766  158375402  49 -0.172014 -0.078182  1.018602   0.028105 -0.043875   \n","\n","               7          8         9  ...       160        161       162  \\\n","3       9.782742  12.414558 -0.163645  ...  0.241406   1.072793  0.085530   \n","9       4.667146   0.851305 -0.163645  ...  0.241406   0.604120  0.008632   \n","10     -0.113002  -0.061584 -0.137933  ...  0.241406   0.018279 -0.087490   \n","11     -0.113002  -0.061584 -0.141519  ... -0.978556   0.018279 -0.087490   \n","16     -0.029140   0.242712 -0.163640  ...  0.241406   0.018279 -0.068266   \n","...          ...        ...       ...  ...       ...        ...       ...   \n","203752 -0.113002  -0.061584 -0.149635  ... -0.388216  -0.098889  1.931078   \n","203754 -0.113002  -0.061584 -0.163622  ...  0.241406  10.914916  1.700384   \n","203759  0.054722  -0.061584 -0.163631  ...  1.461369   0.018279 -0.087490   \n","203763 -0.113002  -0.061584 -0.082559  ...  0.241406   0.018279 -0.087490   \n","203766  0.054722  -0.061584 -0.163626  ...  1.461369   0.018279 -0.087490   \n","\n","             163       164       165       166      txId1      txId2  class  \n","3      -0.131155  0.677799 -0.120613 -0.119792  230333930  230595899      2  \n","9      -0.131155  0.333211 -0.120613 -0.119792  230409257   32877982      2  \n","10     -0.131155 -0.097524 -0.120613 -0.119792  230351738  195218118      2  \n","11     -0.131155 -0.097524 -0.120613 -0.119792   88008478  232012569      2  \n","16     -0.084674 -0.054450 -1.760926 -1.760984  233591710  234439913      2  \n","...          ...       ...       ...       ...        ...        ...    ...  \n","203752  3.168259  3.707301 -1.390548 -1.214035   94245248   94256093      2  \n","203754 -0.131155  7.914145 -0.120613 -0.119792   94137367   93045453      2  \n","203759 -0.131155 -0.097524 -0.120613 -0.119792   91914185   99262892      1  \n","203763 -0.131155 -0.097524 -0.120613 -0.119792   94270539   94270531      2  \n","203766 -0.131155 -0.097524 -0.120613 -0.119792   94284744   94284728      1  \n","\n","[46564 rows x 170 columns]"],"text/html":["\n","  <div id=\"df-091d14c5-bbe1-4557-9400-a2ce28ae16de\">\n","    <div class=\"colab-df-container\">\n","      <div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>0</th>\n","      <th>1</th>\n","      <th>2</th>\n","      <th>3</th>\n","      <th>4</th>\n","      <th>5</th>\n","      <th>6</th>\n","      <th>7</th>\n","      <th>8</th>\n","      <th>9</th>\n","      <th>...</th>\n","      <th>160</th>\n","      <th>161</th>\n","      <th>162</th>\n","      <th>163</th>\n","      <th>164</th>\n","      <th>165</th>\n","      <th>166</th>\n","      <th>txId1</th>\n","      <th>txId2</th>\n","      <th>class</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>3</th>\n","      <td>232438397</td>\n","      <td>1</td>\n","      <td>0.163054</td>\n","      <td>1.963790</td>\n","      <td>-0.646376</td>\n","      <td>12.409294</td>\n","      <td>-0.063725</td>\n","      <td>9.782742</td>\n","      <td>12.414558</td>\n","      <td>-0.163645</td>\n","      <td>...</td>\n","      <td>0.241406</td>\n","      <td>1.072793</td>\n","      <td>0.085530</td>\n","      <td>-0.131155</td>\n","      <td>0.677799</td>\n","      <td>-0.120613</td>\n","      <td>-0.119792</td>\n","      <td>230333930</td>\n","      <td>230595899</td>\n","      <td>2</td>\n","    </tr>\n","    <tr>\n","      <th>9</th>\n","      <td>232029206</td>\n","      <td>1</td>\n","      <td>-0.005027</td>\n","      <td>0.578941</td>\n","      <td>-0.091383</td>\n","      <td>4.380281</td>\n","      <td>-0.063725</td>\n","      <td>4.667146</td>\n","      <td>0.851305</td>\n","      <td>-0.163645</td>\n","      <td>...</td>\n","      <td>0.241406</td>\n","      <td>0.604120</td>\n","      <td>0.008632</td>\n","      <td>-0.131155</td>\n","      <td>0.333211</td>\n","      <td>-0.120613</td>\n","      <td>-0.119792</td>\n","      <td>230409257</td>\n","      <td>32877982</td>\n","      <td>2</td>\n","    </tr>\n","    <tr>\n","      <th>10</th>\n","      <td>232344069</td>\n","      <td>1</td>\n","      <td>-0.147852</td>\n","      <td>-0.184668</td>\n","      <td>-1.201369</td>\n","      <td>-0.121970</td>\n","      <td>-0.043875</td>\n","      <td>-0.113002</td>\n","      <td>-0.061584</td>\n","      <td>-0.137933</td>\n","      <td>...</td>\n","      <td>0.241406</td>\n","      <td>0.018279</td>\n","      <td>-0.087490</td>\n","      <td>-0.131155</td>\n","      <td>-0.097524</td>\n","      <td>-0.120613</td>\n","      <td>-0.119792</td>\n","      <td>230351738</td>\n","      <td>195218118</td>\n","      <td>2</td>\n","    </tr>\n","    <tr>\n","      <th>11</th>\n","      <td>27553029</td>\n","      <td>1</td>\n","      <td>-0.151357</td>\n","      <td>-0.184668</td>\n","      <td>-1.201369</td>\n","      <td>-0.121970</td>\n","      <td>-0.043875</td>\n","      <td>-0.113002</td>\n","      <td>-0.061584</td>\n","      <td>-0.141519</td>\n","      <td>...</td>\n","      <td>-0.978556</td>\n","      <td>0.018279</td>\n","      <td>-0.087490</td>\n","      <td>-0.131155</td>\n","      <td>-0.097524</td>\n","      <td>-0.120613</td>\n","      <td>-0.119792</td>\n","      <td>88008478</td>\n","      <td>232012569</td>\n","      <td>2</td>\n","    </tr>\n","    <tr>\n","      <th>16</th>\n","      <td>3881097</td>\n","      <td>1</td>\n","      <td>-0.172306</td>\n","      <td>-0.184668</td>\n","      <td>-1.201369</td>\n","      <td>0.028105</td>\n","      <td>-0.043875</td>\n","      <td>-0.029140</td>\n","      <td>0.242712</td>\n","      <td>-0.163640</td>\n","      <td>...</td>\n","      <td>0.241406</td>\n","      <td>0.018279</td>\n","      <td>-0.068266</td>\n","      <td>-0.084674</td>\n","      <td>-0.054450</td>\n","      <td>-1.760926</td>\n","      <td>-1.760984</td>\n","      <td>233591710</td>\n","      <td>234439913</td>\n","      <td>2</td>\n","    </tr>\n","    <tr>\n","      <th>...</th>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","    </tr>\n","    <tr>\n","      <th>203752</th>\n","      <td>80329479</td>\n","      <td>49</td>\n","      <td>-0.159293</td>\n","      <td>-0.037276</td>\n","      <td>1.018602</td>\n","      <td>-0.121970</td>\n","      <td>0.035526</td>\n","      <td>-0.113002</td>\n","      <td>-0.061584</td>\n","      <td>-0.149635</td>\n","      <td>...</td>\n","      <td>-0.388216</td>\n","      <td>-0.098889</td>\n","      <td>1.931078</td>\n","      <td>3.168259</td>\n","      <td>3.707301</td>\n","      <td>-1.390548</td>\n","      <td>-1.214035</td>\n","      <td>94245248</td>\n","      <td>94256093</td>\n","      <td>2</td>\n","    </tr>\n","    <tr>\n","      <th>203754</th>\n","      <td>158406298</td>\n","      <td>49</td>\n","      <td>-0.172962</td>\n","      <td>-0.126566</td>\n","      <td>1.018602</td>\n","      <td>-0.121970</td>\n","      <td>-0.063725</td>\n","      <td>-0.113002</td>\n","      <td>-0.061584</td>\n","      <td>-0.163622</td>\n","      <td>...</td>\n","      <td>0.241406</td>\n","      <td>10.914916</td>\n","      <td>1.700384</td>\n","      <td>-0.131155</td>\n","      <td>7.914145</td>\n","      <td>-0.120613</td>\n","      <td>-0.119792</td>\n","      <td>94137367</td>\n","      <td>93045453</td>\n","      <td>2</td>\n","    </tr>\n","    <tr>\n","      <th>203759</th>\n","      <td>158375075</td>\n","      <td>49</td>\n","      <td>-0.170412</td>\n","      <td>-0.078164</td>\n","      <td>1.018602</td>\n","      <td>0.028105</td>\n","      <td>-0.043875</td>\n","      <td>0.054722</td>\n","      <td>-0.061584</td>\n","      <td>-0.163631</td>\n","      <td>...</td>\n","      <td>1.461369</td>\n","      <td>0.018279</td>\n","      <td>-0.087490</td>\n","      <td>-0.131155</td>\n","      <td>-0.097524</td>\n","      <td>-0.120613</td>\n","      <td>-0.119792</td>\n","      <td>91914185</td>\n","      <td>99262892</td>\n","      <td>1</td>\n","    </tr>\n","    <tr>\n","      <th>203763</th>\n","      <td>147478192</td>\n","      <td>49</td>\n","      <td>-0.093732</td>\n","      <td>-0.116160</td>\n","      <td>1.018602</td>\n","      <td>-0.121970</td>\n","      <td>-0.043875</td>\n","      <td>-0.113002</td>\n","      <td>-0.061584</td>\n","      <td>-0.082559</td>\n","      <td>...</td>\n","      <td>0.241406</td>\n","      <td>0.018279</td>\n","      <td>-0.087490</td>\n","      <td>-0.131155</td>\n","      <td>-0.097524</td>\n","      <td>-0.120613</td>\n","      <td>-0.119792</td>\n","      <td>94270539</td>\n","      <td>94270531</td>\n","      <td>2</td>\n","    </tr>\n","    <tr>\n","      <th>203766</th>\n","      <td>158375402</td>\n","      <td>49</td>\n","      <td>-0.172014</td>\n","      <td>-0.078182</td>\n","      <td>1.018602</td>\n","      <td>0.028105</td>\n","      <td>-0.043875</td>\n","      <td>0.054722</td>\n","      <td>-0.061584</td>\n","      <td>-0.163626</td>\n","      <td>...</td>\n","      <td>1.461369</td>\n","      <td>0.018279</td>\n","      <td>-0.087490</td>\n","      <td>-0.131155</td>\n","      <td>-0.097524</td>\n","      <td>-0.120613</td>\n","      <td>-0.119792</td>\n","      <td>94284744</td>\n","      <td>94284728</td>\n","      <td>1</td>\n","    </tr>\n","  </tbody>\n","</table>\n","<p>46564 rows × 170 columns</p>\n","</div>\n","      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-091d14c5-bbe1-4557-9400-a2ce28ae16de')\"\n","              title=\"Convert this dataframe to an interactive table.\"\n","              style=\"display:none;\">\n","        \n","  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n","       width=\"24px\">\n","    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n","    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n","  </svg>\n","      </button>\n","      \n","  <style>\n","    .colab-df-container {\n","      display:flex;\n","      flex-wrap:wrap;\n","      gap: 12px;\n","    }\n","\n","    .colab-df-convert {\n","      background-color: #E8F0FE;\n","      border: none;\n","      border-radius: 50%;\n","      cursor: pointer;\n","      display: none;\n","      fill: #1967D2;\n","      height: 32px;\n","      padding: 0 0 0 0;\n","      width: 32px;\n","    }\n","\n","    .colab-df-convert:hover {\n","      background-color: #E2EBFA;\n","      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n","      fill: #174EA6;\n","    }\n","\n","    [theme=dark] .colab-df-convert {\n","      background-color: #3B4455;\n","      fill: #D2E3FC;\n","    }\n","\n","    [theme=dark] .colab-df-convert:hover {\n","      background-color: #434B5C;\n","      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n","      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n","      fill: #FFFFFF;\n","    }\n","  </style>\n","\n","      <script>\n","        const buttonEl =\n","          document.querySelector('#df-091d14c5-bbe1-4557-9400-a2ce28ae16de button.colab-df-convert');\n","        buttonEl.style.display =\n","          google.colab.kernel.accessAllowed ? 'block' : 'none';\n","\n","        async function convertToInteractive(key) {\n","          const element = document.querySelector('#df-091d14c5-bbe1-4557-9400-a2ce28ae16de');\n","          const dataTable =\n","            await google.colab.kernel.invokeFunction('convertToInteractive',\n","                                                     [key], {});\n","          if (!dataTable) return;\n","\n","          const docLinkHtml = 'Like what you see? Visit the ' +\n","            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n","            + ' to learn more about interactive tables.';\n","          element.innerHTML = '';\n","          dataTable['output_type'] = 'display_data';\n","          await google.colab.output.renderOutput(dataTable, element);\n","          const docLink = document.createElement('div');\n","          docLink.innerHTML = docLinkHtml;\n","          element.appendChild(docLink);\n","        }\n","      </script>\n","    </div>\n","  </div>\n","  "]},"metadata":{},"execution_count":39}]},{"cell_type":"code","source":["x = dataset.iloc[:,1:169]\n","y = dataset['class']\n","x_tr,x_val,y_tr,y_val = train_test_split(x,y, test_size=0.30,random_state=28)\n"],"metadata":{"id":"oImVKdkBAQEB","executionInfo":{"status":"ok","timestamp":1677685971094,"user_tz":-60,"elapsed":1125,"user":{"displayName":"Marco Acerbis","userId":"06213734805574553664"}}},"execution_count":46,"outputs":[]},{"cell_type":"code","source":["rfc= RFC(criterion = 'entropy' , n_estimators =100 , random_state = 28 , n_jobs =3)\n","#rfc= RFC(criterion = 'gini' , n_estimators = 100 , random_state = 28 )\n","rfc.fit(x_tr,y_tr)"],"metadata":{"id":"CXFx10XMG5Gb","executionInfo":{"status":"ok","timestamp":1677686223775,"user_tz":-60,"elapsed":24143,"user":{"displayName":"Marco Acerbis","userId":"06213734805574553664"}},"colab":{"base_uri":"https://localhost:8080/"},"outputId":"eeb03ed4-719d-4e2f-9d3e-4c317301a470"},"execution_count":56,"outputs":[{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.8/dist-packages/sklearn/utils/validation.py:1688: FutureWarning: Feature names only support names that are all strings. Got feature names with dtypes: ['int', 'str']. An error will be raised in 1.2.\n","  warnings.warn(\n"]},{"output_type":"execute_result","data":{"text/plain":["RandomForestClassifier(criterion='entropy', n_estimators=200, n_jobs=3,\n","                       random_state=28)"]},"metadata":{},"execution_count":56}]},{"cell_type":"code","source":["pred = rfc.predict(x_val)\n","cm = confusion_matrix(y_val,pred)\n","cm"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"Is3dbO-yKvLO","executionInfo":{"status":"ok","timestamp":1677686229854,"user_tz":-60,"elapsed":1019,"user":{"displayName":"Marco Acerbis","userId":"06213734805574553664"}},"outputId":"d0ae7fbc-7e63-4a8d-f327-89a568689230"},"execution_count":57,"outputs":[{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.8/dist-packages/sklearn/utils/validation.py:1688: FutureWarning: Feature names only support names that are all strings. Got feature names with dtypes: ['int', 'str']. An error will be raised in 1.2.\n","  warnings.warn(\n"]},{"output_type":"execute_result","data":{"text/plain":["array([[ 1189,   155],\n","       [    5, 12621]])"]},"metadata":{},"execution_count":57}]},{"cell_type":"code","source":["F1 = f1_score(y_val,pred,pos_label='1')\n","Recall = recall_score(y_val,pred,pos_label='1')\n","Precision = precision_score(y_val,pred,pos_label='1')\n","\n","print('Precision: ', Precision,' Recall: ', Recall, ' F1: ', F1)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"Flw9Ec112bVO","executionInfo":{"status":"ok","timestamp":1677687101133,"user_tz":-60,"elapsed":885,"user":{"displayName":"Marco Acerbis","userId":"06213734805574553664"}},"outputId":"c44c2f56-1f1f-4f76-ddd0-d8c566088a3c"},"execution_count":65,"outputs":[{"output_type":"stream","name":"stdout","text":["Precision:  0.9958123953098827  Recall:  0.8846726190476191  F1:  0.9369582348305753\n"]}]},{"cell_type":"code","source":["rfc.fit(train_embs.cpu(),train_lbls.cpu())"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"TB8mGCR_PlQE","executionInfo":{"status":"ok","timestamp":1677686707458,"user_tz":-60,"elapsed":19040,"user":{"displayName":"Marco Acerbis","userId":"06213734805574553664"}},"outputId":"12b99034-cb5f-44d1-e641-183bcc134235"},"execution_count":59,"outputs":[{"output_type":"execute_result","data":{"text/plain":["RandomForestClassifier(criterion='entropy', n_estimators=200, n_jobs=3,\n","                       random_state=28)"]},"metadata":{},"execution_count":59}]},{"cell_type":"code","source":["pred_embs = rfc.predict(test_embs.cpu())\n","cm = confusion_matrix(test_lbls.cpu(),pred_embs)\n","cm"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"blQIRIXsTfMx","executionInfo":{"status":"ok","timestamp":1677686707459,"user_tz":-60,"elapsed":7,"user":{"displayName":"Marco Acerbis","userId":"06213734805574553664"}},"outputId":"11e6d811-aa6e-46e9-e682-b6724288430d"},"execution_count":60,"outputs":[{"output_type":"execute_result","data":{"text/plain":["array([[1908,  143],\n","       [  29,  193]])"]},"metadata":{},"execution_count":60}]},{"cell_type":"code","source":["F1 = f1_score(test_lbls.cpu(),pred_embs,pos_label=0)\n","Recall = recall_score(test_lbls.cpu(),pred_embs,pos_label=0)\n","Precision = precision_score(test_lbls.cpu(),pred_embs,pos_label=0)\n","\n","print('Precision: ', Precision,' Recall: ', Recall, ' F1: ', F1)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"aWbI1BBoT6Q3","executionInfo":{"status":"ok","timestamp":1677687110735,"user_tz":-60,"elapsed":417,"user":{"displayName":"Marco Acerbis","userId":"06213734805574553664"}},"outputId":"77f7d7db-1793-46ea-adbc-eba9f82add46"},"execution_count":66,"outputs":[{"output_type":"stream","name":"stdout","text":["Precision:  0.9850283944243676  Recall:  0.9302779132130667  F1:  0.9568706118355066\n"]}]},{"cell_type":"code","source":[],"metadata":{"id":"-mr0aqI-2Tqa"},"execution_count":null,"outputs":[]}]}